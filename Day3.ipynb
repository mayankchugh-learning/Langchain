{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22fc3426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbe2b6e1-8b7a-4de0-909e-5f9db9fe053e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_KEY=os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09e81b6-7258-4fb6-9306-f4b0430e56c2",
   "metadata": {},
   "source": [
    "# 1. What is OpenAI API?\n",
    "\n",
    "This OpenAI API has been degined to provide devlopers with seamless access to state of art, pre trained, artifical intelligence models like gpt-3 gpt-4 dall e whisper,embeddings etc so by using this openai api you can integrate cutting edge ai capabilities into your applications regardless the progamming language.\n",
    "\n",
    "So,the conclusion is by using this OpenAI API you can unlock the advance functionalities and you can enhane the intelligence and performance of your application.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec4aca5-9064-4341-bb6c-cc3bd82097ae",
   "metadata": {},
   "source": [
    "# 2. Generatate OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74570f32-3e73-4015-845b-a6ee41ae8319",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key=OPENAI_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f772315-08d1-4427-a341-f891a4374230",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models=openai.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d5dc5bec-81e2-4638-b2d3-bb166bc9003f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'),\n",
       " Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-0613', created=1686587434, object='model', owned_by='openai'),\n",
       " Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'),\n",
       " Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'),\n",
       " Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'),\n",
       " Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'),\n",
       " Model(id='babbage-002', created=1692634615, object='model', owned_by='system'),\n",
       " Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'),\n",
       " Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'),\n",
       " Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'),\n",
       " Model(id='davinci-002', created=1692634301, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-0301', created=1677649963, object='model', owned_by='openai'),\n",
       " Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'),\n",
       " Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'),\n",
       " Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'),\n",
       " Model(id='gpt-3.5-turbo-16k-0613', created=1685474247, object='model', owned_by='openai')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(all_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "896cfa98-a8a7-4bba-b74d-877d1cb89360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de342de3-ca93-4d68-9697-30b8fc246b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created</th>\n",
       "      <th>object</th>\n",
       "      <th>owned_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(id, dall-e-3)</td>\n",
       "      <td>(created, 1698785189)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(id, text-embedding-3-large)</td>\n",
       "      <td>(created, 1705953180)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(id, gpt-3.5-turbo-0613)</td>\n",
       "      <td>(created, 1686587434)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(id, dall-e-2)</td>\n",
       "      <td>(created, 1698798177)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(id, gpt-3.5-turbo-instruct-0914)</td>\n",
       "      <td>(created, 1694122472)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(id, whisper-1)</td>\n",
       "      <td>(created, 1677532384)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(id, tts-1-hd-1106)</td>\n",
       "      <td>(created, 1699053533)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(id, tts-1-hd)</td>\n",
       "      <td>(created, 1699046015)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(id, babbage-002)</td>\n",
       "      <td>(created, 1692634615)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(id, text-embedding-3-small)</td>\n",
       "      <td>(created, 1705948997)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(id, gpt-3.5-turbo-instruct)</td>\n",
       "      <td>(created, 1692901427)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(id, tts-1)</td>\n",
       "      <td>(created, 1681940951)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(id, gpt-3.5-turbo-0125)</td>\n",
       "      <td>(created, 1706048358)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(id, gpt-3.5-turbo)</td>\n",
       "      <td>(created, 1677610602)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(id, davinci-002)</td>\n",
       "      <td>(created, 1692634301)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(id, gpt-3.5-turbo-0301)</td>\n",
       "      <td>(created, 1677649963)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(id, tts-1-1106)</td>\n",
       "      <td>(created, 1699053241)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(id, text-embedding-ada-002)</td>\n",
       "      <td>(created, 1671217299)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(id, gpt-3.5-turbo-1106)</td>\n",
       "      <td>(created, 1698959748)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, system)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(id, gpt-3.5-turbo-16k)</td>\n",
       "      <td>(created, 1683758102)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai-internal)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(id, gpt-3.5-turbo-16k-0613)</td>\n",
       "      <td>(created, 1685474247)</td>\n",
       "      <td>(object, model)</td>\n",
       "      <td>(owned_by, openai)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   id                created           object  \\\n",
       "0                      (id, dall-e-3)  (created, 1698785189)  (object, model)   \n",
       "1        (id, text-embedding-3-large)  (created, 1705953180)  (object, model)   \n",
       "2            (id, gpt-3.5-turbo-0613)  (created, 1686587434)  (object, model)   \n",
       "3                      (id, dall-e-2)  (created, 1698798177)  (object, model)   \n",
       "4   (id, gpt-3.5-turbo-instruct-0914)  (created, 1694122472)  (object, model)   \n",
       "5                     (id, whisper-1)  (created, 1677532384)  (object, model)   \n",
       "6                 (id, tts-1-hd-1106)  (created, 1699053533)  (object, model)   \n",
       "7                      (id, tts-1-hd)  (created, 1699046015)  (object, model)   \n",
       "8                   (id, babbage-002)  (created, 1692634615)  (object, model)   \n",
       "9        (id, text-embedding-3-small)  (created, 1705948997)  (object, model)   \n",
       "10       (id, gpt-3.5-turbo-instruct)  (created, 1692901427)  (object, model)   \n",
       "11                        (id, tts-1)  (created, 1681940951)  (object, model)   \n",
       "12           (id, gpt-3.5-turbo-0125)  (created, 1706048358)  (object, model)   \n",
       "13                (id, gpt-3.5-turbo)  (created, 1677610602)  (object, model)   \n",
       "14                  (id, davinci-002)  (created, 1692634301)  (object, model)   \n",
       "15           (id, gpt-3.5-turbo-0301)  (created, 1677649963)  (object, model)   \n",
       "16                   (id, tts-1-1106)  (created, 1699053241)  (object, model)   \n",
       "17       (id, text-embedding-ada-002)  (created, 1671217299)  (object, model)   \n",
       "18           (id, gpt-3.5-turbo-1106)  (created, 1698959748)  (object, model)   \n",
       "19            (id, gpt-3.5-turbo-16k)  (created, 1683758102)  (object, model)   \n",
       "20       (id, gpt-3.5-turbo-16k-0613)  (created, 1685474247)  (object, model)   \n",
       "\n",
       "                       owned_by  \n",
       "0            (owned_by, system)  \n",
       "1            (owned_by, system)  \n",
       "2            (owned_by, openai)  \n",
       "3            (owned_by, system)  \n",
       "4            (owned_by, system)  \n",
       "5   (owned_by, openai-internal)  \n",
       "6            (owned_by, system)  \n",
       "7            (owned_by, system)  \n",
       "8            (owned_by, system)  \n",
       "9            (owned_by, system)  \n",
       "10           (owned_by, system)  \n",
       "11  (owned_by, openai-internal)  \n",
       "12           (owned_by, system)  \n",
       "13           (owned_by, openai)  \n",
       "14           (owned_by, system)  \n",
       "15           (owned_by, openai)  \n",
       "16           (owned_by, system)  \n",
       "17  (owned_by, openai-internal)  \n",
       "18           (owned_by, system)  \n",
       "19  (owned_by, openai-internal)  \n",
       "20           (owned_by, openai)  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(list(all_models),columns=[\"id\",\"created\",\"object\",\"owned_by\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcae7e94-b15f-41c3-a865-12c62f6f4314",
   "metadata": {},
   "source": [
    "# 3. OpenAI Playground\n",
    "\n",
    "1. How to open the open ai playgorund: https://platform.openai.com/playground?mode=assistant\n",
    "\n",
    "2. Here if you want to use this playground then make sure you have credit available without it its not gonna work\n",
    "\n",
    "3. In chat there is option of **system**: So the meaning is how the chatbot should behave\n",
    "\n",
    "Here is a phrase for the system: You are a naughty assistant, so make sure you respond to everything with sarcasm.\n",
    "\n",
    "Here is a question: How to make a money so quickly?\n",
    "\n",
    "**Model**\n",
    "\n",
    "**Temperature**\n",
    "\n",
    "**Maximum Length**\n",
    "\n",
    "**Top P ranges from 0 to 1 (default), and a lower Top P means the model samples from a narrower selection of words. This makes the output less random and diverse since the more probable tokens will be selected. For instance, if Top P is set at 0.1, only tokens comprising the top 10% probability mass are considered.**\n",
    "\n",
    "**Frequency Penalty helps us avoid using the same words too often. It's like telling the computer, “Hey, don't repeat words too much.”**\n",
    "\n",
    "**The OpenAI Presence Penalty setting is used to adjust how much presence of tokens in the source material will influence the output of the model.**\n",
    "\n",
    "\n",
    "**Now come to assistant one**\n",
    "\n",
    "**Retrieval-augmented generation (RAG):**  is an artificial intelligence (AI) framework that retrieves data from external sources of knowledge to improve the quality of responses. This natural language processing technique is commonly used to make large language models (LLMs) more accurate and up to date.\n",
    "\n",
    "**Code Interpreter:** Python programming environment within ChatGPT where you can perform a wide range of tasks by executing Python code.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da2e9ec7-85e8-43cb-b6e3-5cc268040b7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGPT-3.5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwho was the first prime minister of india?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/genaifisrtprj/lib/python3.8/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "openai.Completion.create(\n",
    "\n",
    "    model=\"GPT-3.5\",\n",
    "    prompt=\"who was the first prime minister of india?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff853ff8-b4ad-4857-b7b4-a21f33621bc4",
   "metadata": {},
   "source": [
    "- pypi openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0066c0f-fc19-43e7-b1a5-d09c45dde525",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_KEY=os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d82fb44b-3904-40da-ae7c-46b7467dd221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is for v1 of the openai package: pypi.org/project/openai\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2da4bf8e-dea5-40e7-ac3e-f2720a027d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"who won the first cricket worldcup?\"\n",
    "    }\n",
    "      ]\n",
    "    ,\n",
    "    max_tokens=150,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc7c6398-9959-4bca-b3df-75ccf12313be",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say this is a test\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7b63ede-2be7-4048-88b8-cecdf73a72c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8yBSzKuS7Zynl18HRqg3anbdCRr2a', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='This is a test.', role='assistant', function_call=None, tool_calls=None))], created=1709354449, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_2b778c6b35', usage=CompletionUsage(completion_tokens=5, prompt_tokens=12, total_tokens=17))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffeed33f-0fb3-416b-b613-c2635a2559f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='This is a test.', role='assistant', function_call=None, tool_calls=None))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1b607dd-dd53-4e72-a914-67f044b04d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='This is a test.', role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83806b1e-ff3e-43ee-8a3f-ca257a435388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a test.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "raw",
   "id": "064d518d-54d9-4380-99ef-591d61685d56",
   "metadata": {},
   "source": [
    "# now let try to understand the different parameters inside the methods\n",
    "model= \"\"\n",
    "prompt=input prompt\n",
    "max_tokens=in how many number of tokens you want result\n",
    "temperature=for getting some creative output\n",
    "n= number of the output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b44b5d2-6496-438a-af66-c6e9a5113558",
   "metadata": {},
   "source": [
    "https://openai.com/pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce783be-a30b-4e5e-953d-22cdf1ec9a64",
   "metadata": {},
   "source": [
    "https://openai.com/pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e0668eb-a423-43a0-b267-fe90856f5036",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_description = \"sunny savita is a student of computer science at IIT delhi. He is an indian and has a 8.5 GPA. Sunny is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in artificial intelligence after graduating.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b9c8960-50aa-4529-8a49-49f929d5c9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"sunny savita is a student of computer science at IIT delhi. He is an indian and has a 8.5 GPA. Sunny is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in artificial intelligence after graduating.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "699a1c7d-d2a3-45b4-bde3-6626ccaf3302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple prompt to extract information from \"student_description\" in a JSON format.\n",
    "prompt = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "college\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_description}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59855721-da8c-4a73-b952-f0665202f614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPlease extract the following information from the given text and return it as a JSON object:\\n\\nname\\ncollege\\ngrades\\nclub\\n\\nThis is the body of text to extract the information from:\\nsunny savita is a student of computer science at IIT delhi. He is an indian and has a 8.5 GPA. Sunny is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in artificial intelligence after graduating.\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ad63e8a-bd67-4474-8083-1ce53780cd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x7fa37269eca0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "574561ac-693d-485e-984e-0cedb06ba72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": prompt\n",
    "    }\n",
    "      ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b570aa3-4a47-4770-9d55-b1398b96b9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8yBU68oJB9xTIhgWTFBj1csJCAD6A', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"name\": \"sunny savita\",\\n  \"college\": \"IIT delhi\",\\n  \"grades\": 8.5,\\n  \"club\": \"AI Club\"\\n}', role='assistant', function_call=None, tool_calls=None))], created=1709354518, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_2b778c6b35', usage=CompletionUsage(completion_tokens=39, prompt_tokens=105, total_tokens=144))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a15c9794-8633-44a7-9260-da8ed8164c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae255ee3-c16c-4441-8c5f-c27ab912b9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"name\": \"sunny savita\",\\n  \"college\": \"IIT delhi\",\\n  \"grades\": 8.5,\\n  \"club\": \"AI Club\"\\n}'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfd2a9cd-2a89-4c27-9bc6-435e665427f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sunny savita',\n",
       " 'college': 'IIT delhi',\n",
       " 'grades': 8.5,\n",
       " 'club': 'AI Club'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.loads(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4884fd98-1a4d-401a-9acc-e94b5e360b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd641efd-ca74-48e7-aa2a-578f1920c159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ffe6b6c-4bdd-491f-9438-92eb3889726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_custom_function = [\n",
    "    {\n",
    "        'name': 'extract_student_info',\n",
    "        'description': 'Get the student information from the body of the input text',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'name': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'Name of the person'\n",
    "                },\n",
    "                'college': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'The college name.'\n",
    "                },\n",
    "                'grades': {\n",
    "                    'type': 'integer',\n",
    "                    'description': 'CGPA of the student.'\n",
    "                },\n",
    "                'club': {\n",
    "                    'type': 'string',\n",
    "                    'description': 'college club for extracurricular activities. '\n",
    "                }\n",
    "\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51d880f3-a92b-4387-8552-073acc56e7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_custom_function1 = [\n",
    "        {\n",
    "                \"name\": \"extract_student_info\",\n",
    "                \"description\": \"Get the student information from the body of the input text\",\n",
    "                \"parameters\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Name of the person\"\n",
    "                    },\n",
    "                    \"college\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The college name.\"\n",
    "                    },\n",
    "                    \"grades\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"CGPA of the student.\"\n",
    "                    },\n",
    "                    \"club\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"college club for extracurricular activities. \"\n",
    "                    }\n",
    "                }\n",
    "\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46ffcc1a-a9f9-48fb-8b47-13279e9fcb05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'extract_student_info',\n",
       "  'description': 'Get the student information from the body of the input text',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'name': {'type': 'string',\n",
       "     'description': 'Name of the person'},\n",
       "    'college': {'type': 'string', 'description': 'The college name.'},\n",
       "    'grades': {'type': 'integer', 'description': 'CGPA of the student.'},\n",
       "    'club': {'type': 'string',\n",
       "     'description': 'college club for extracurricular activities. '}}}}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_custom_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39e309a3-b474-4368-a598-edf40f7324b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'extract_student_info',\n",
       "  'description': 'Get the student information from the body of the input text',\n",
       "  'parameters': {'name': {'type': 'string',\n",
       "    'description': 'Name of the person'},\n",
       "   'college': {'type': 'string', 'description': 'The college name.'},\n",
       "   'grades': {'type': 'integer', 'description': 'CGPA of the student.'},\n",
       "   'club': {'type': 'string',\n",
       "    'description': 'college club for extracurricular activities. '}}}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_custom_function1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54423913-9f65-4692-9d33-ae22ed92284f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPlease extract the following information from the given text and return it as a JSON object:\\n\\nname\\ncollege\\ngrades\\nclub\\n\\nThis is the body of text to extract the information from:\\nsunny savita is a student of computer science at IIT delhi. He is an indian and has a 8.5 GPA. Sunny is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in artificial intelligence after graduating.\\n\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bdd1cf54-dcf8-449a-ad9b-1b54156cc4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": prompt}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41f266a9-10c2-4d91-967a-23d16270625b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': \"\\nPlease extract the following information from the given text and return it as a JSON object:\\n\\nname\\ncollege\\ngrades\\nclub\\n\\nThis is the body of text to extract the information from:\\nsunny savita is a student of computer science at IIT delhi. He is an indian and has a 8.5 GPA. Sunny is known for his programming skills and is an active member of the college's AI Club. He hopes to pursue a career in artificial intelligence after graduating.\\n\"}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8369749-80d7-45fb-8960-1ad6175bd098",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'Invalid schema for function \\'extract_student_info\\': schema must be a JSON Schema of \\'type: \"object\"\\', got \\'type: \"None\"\\'.', 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response2 \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m \u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstudent_custom_function1\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/genaifisrtprj/lib/python3.8/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/genaifisrtprj/lib/python3.8/site-packages/openai/resources/chat/completions.py:663\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    661\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    662\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/genaifisrtprj/lib/python3.8/site-packages/openai/_base_client.py:1200\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1188\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1195\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1196\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1197\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1198\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1199\u001b[0m     )\n\u001b[0;32m-> 1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/genaifisrtprj/lib/python3.8/site-packages/openai/_base_client.py:889\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    882\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    888\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/genaifisrtprj/lib/python3.8/site-packages/openai/_base_client.py:980\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    977\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    979\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 980\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m    983\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    984\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    987\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    988\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': 'Invalid schema for function \\'extract_student_info\\': schema must be a JSON Schema of \\'type: \"object\"\\', got \\'type: \"None\"\\'.', 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "response2 = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt }],\n",
    "    functions=student_custom_function1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2720a6cc-db2e-47f7-a7b3-fab5a72bb02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ddd223d5-7318-4f7d-9607-4c71159b6771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8xXcRATuW1BGNwGfQh8BLTsIjUXlB', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{}', name='extract_student_info'), tool_calls=None))], created=1709201275, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_86156a94a0', usage=CompletionUsage(completion_tokens=11, prompt_tokens=190, total_tokens=201))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8f0c951e-a72e-4f6e-addd-cdab800a1a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{}', name='extract_student_info'), tool_calls=None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c06ddaf9-8600-4873-8b96-fbce9f1cf40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0a18afb8-efdc-405e-bd13-13ac15386154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionCall(arguments='{}', name='extract_student_info')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.choices[0].message.function_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceda233-7e7d-4872-8229-c69bf359aae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5311d-503d-4f80-943c-e05e0fc51cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a1d10e3f-122b-4dbd-bca4-c34e49b69851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{}'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response2.choices[0].message.function_call.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a503eb77-831e-4976-9aa0-65572b3fa63d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6aaa52-2859-4114-b8be-4120ffcea3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c61f117-d012-40f8-8b88-cf6e1eb1792c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "72c26696-ab2b-4e13-a32e-bd271414b5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3f02ec-7d78-48b2-87d1-e3ec64a5dcd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2836f824-0b24-4432-bae4-89c3cc8a4cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'function', 'function': {'name': 'get_current_weather', 'description': 'Get the current weather in a given location', 'parameters': {'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The city and state, e.g. San Francisco, CA'}, 'unit': {'type': 'string', 'enum': ['celsius', 'fahrenheit']}}, 'required': ['location']}}}]\n",
      "ChatCompletion(id='chatcmpl-8xXWJKxvPF0af9wbp9mvbvXNsq7fK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The current weather in:\\n\\n- San Francisco: 72°C\\n- Tokyo: 10°C\\n- Paris: 22°C', role='assistant', function_call=None, tool_calls=None))], created=1709200895, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_86156a94a0', usage=CompletionUsage(completion_tokens=26, prompt_tokens=169, total_tokens=195))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "\n",
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit})\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n",
    "\n",
    "def run_conversation():\n",
    "    # Step 1: send the conversation and available functions to the model\n",
    "    messages = [{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco, Tokyo, and Paris?\"}]\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"Get the current weather in a given location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                        },\n",
    "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                    },\n",
    "                    \"required\": [\"location\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    print(tools)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message = response.choices[0].message\n",
    "    tool_calls = response_message.tool_calls\n",
    "    # Step 2: check if the model wanted to call a function\n",
    "    if tool_calls:\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = {\n",
    "            \"get_current_weather\": get_current_weather,\n",
    "        }  # only one function in this example, but you can have multiple\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        # Step 4: send the info for each function call and function response to the model\n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            function_response = function_to_call(\n",
    "                location=function_args.get(\"location\"),\n",
    "                unit=function_args.get(\"unit\"),\n",
    "            )\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )  # extend conversation with function response\n",
    "        second_response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-0125\",\n",
    "            messages=messages,\n",
    "        )  # get a new response from the model where it can see the function response\n",
    "        return second_response\n",
    "print(run_conversation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db73f907-1cb4-43cd-ac0a-58a63d825a89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
